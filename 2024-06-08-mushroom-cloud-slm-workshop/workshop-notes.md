- Create Ollama local server .

- 中文训练语料库

    弱智吧

- fine-tuning and RAG
    
    SLM is more suitable for fine-tuning than LLM.
    
    RAG
    
    Fine-tuning is suitable for specialized industry's use case, so the answer is more accurate.


- Microsoft Olive architecture

    Define input model, output model, training dataset.

- Content Censorship

    /set system "this is a centent censorship administrator"
    and 
    /set format json

    

# Reference

- [Olive: A user-friendly toolchain for hardware-aware model optimization](https://cloudblogs.microsoft.com/opensource/2023/06/26/olive-a-user-friendly-toolchain-for-hardware-aware-model-optimization/)


